{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "metadata": {
        "id": "ee_x9Yq5hTuO",
        "outputId": "6a3cc436-4377-4826-dd2a-4c4b9719adaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pymagnitude git+https://github.com/huggingface/pytorch-pretrained-BERT.git -q"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "metadata": {
        "id": "jy3gtheyFkHz",
        "outputId": "c65726df-9062-450d-9d32-cea22d12cdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.24.22)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.11.0+cu113)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.22 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.27.22)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.22->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.22->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.22->boto3->pytorch_pretrained_bert) (1.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vuNg51plR2GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0eafdb-7016-48cf-cc99-7b4fe419da6c"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_formats = ['svg']\n",
        "\n",
        "import random\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "#from pymagnitude import Magnitude\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "# If the machine you run this on has a GPU available with CUDA installed,\n",
        "# use it. Using a GPU for learning often leads to huge speedups in training.\n",
        "# See https://developer.nvidia.com/cuda-downloads for installing CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "VubeUOb2tZGU"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning BERT for Text Classification\n",
        "\n",
        "While transfer learning has had a huge impact on image-based deep learning tasks, transfer learning is still a relatively new concept in NLP. The idea is that you first train a large model on a huge amount of data, and then you fine-tune the model on a smaller subset of data.\n",
        "\n",
        "For example, we can train a large model on all of Wikipedia, then fine-tune our model on blog posts about statistics in order for our model to be able to identify the names of people in the blog posts about statistics. The model is able to leverage general understanding of language from Wikipedia to the specific task of identifying people in statistics blog posts.\n",
        "\n",
        "The architecture of BERT is similar, and potentially the next iteration of. The architecture of the GPT-2. The GPT-2 of course uses OpenAI's Transformer, however the model can only look foward when predicting the next word in a sequence. That is to say that is is not *bidirectional*. Therefore, the GPT-2 model is more suited just as a language model for generating text than it is as a text classifier. If we want to build a solid text classifier, we should hope that we are able to consider both words before and after when looking at the text.\n",
        "\n",
        "BERT is a **masked language model**. 15% of the input words are masked, or replaced by a special mask token. For every masked word, the model tries to use the output of the masked word to predict what the word is.\n",
        "\n",
        "![bert overview](http://jalammar.github.io/images/BERT-language-modeling-masked-lm.png)\n",
        "\n",
        "BERT can be setup to perform a number of NLP tasks such as text classification.\n",
        "\n",
        "![bert tasks](http://jalammar.github.io/images/bert-tasks.png)\n",
        "\n",
        "- Great blog post on BERT and the source of illustrations: [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/train.tsv', sep='\\t')\n",
        "data_val = pd.read_csv('/content/validation.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "jo6rDdCsGlYP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to lowercase\n",
        "data['clean_text']=data['Tweet'].str.lower()\n",
        "#remove URLS\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
        "#remove punctuations\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
        "#remove empty lines\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
        "#remove digits\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
        "#remove multiple spaces\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
        "#remove single character\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))"
      ],
      "metadata": {
        "id": "xHiQsSLPGr6z"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_val"
      ],
      "metadata": {
        "id": "16_l5bChL9sC",
        "outputId": "7ab7faf7-68ec-4a14-95a8-a76ebfe2069d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweet                Claim  \\\n",
              "0    Ordered a mask that had a cute chain attached ...           face masks   \n",
              "1    Who is ready for some #baseball?  #BaseballisB...  stay at home orders   \n",
              "2    '@Mystere07623203 @va_shiva @Liberty13046 130,...           face masks   \n",
              "3    When they ask me what I did with my life I wil...           face masks   \n",
              "4    Taylor not putting her album in physical store...  stay at home orders   \n",
              "..                                                 ...                  ...   \n",
              "595  @BrianKempGA is one of the few #Governors that...           face masks   \n",
              "596  'I tested positive for Covid. Got it from a fr...           face masks   \n",
              "597  'If you are under retirement age, you have a *...  stay at home orders   \n",
              "598  '@TheLalasventure @doqholliday @realDonaldTrum...           face masks   \n",
              "599  @Caissie Obviously I was simply practicing my ...           face masks   \n",
              "\n",
              "      Stance  Premise  \n",
              "0      FAVOR        0  \n",
              "1       NONE        0  \n",
              "2      FAVOR        1  \n",
              "3      FAVOR        0  \n",
              "4      FAVOR        0  \n",
              "..       ...      ...  \n",
              "595  AGAINST        1  \n",
              "596    FAVOR        1  \n",
              "597  AGAINST        1  \n",
              "598    FAVOR        0  \n",
              "599    FAVOR        0  \n",
              "\n",
              "[600 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a795fe9-aabf-4d59-8c99-38fdfd70346c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Claim</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Premise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ordered a mask that had a cute chain attached ...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who is ready for some #baseball?  #BaseballisB...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>NONE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'@Mystere07623203 @va_shiva @Liberty13046 130,...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When they ask me what I did with my life I wil...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Taylor not putting her album in physical store...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>@BrianKempGA is one of the few #Governors that...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>'I tested positive for Covid. Got it from a fr...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>'If you are under retirement age, you have a *...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>'@TheLalasventure @doqholliday @realDonaldTrum...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>@Caissie Obviously I was simply practicing my ...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a795fe9-aabf-4d59-8c99-38fdfd70346c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a795fe9-aabf-4d59-8c99-38fdfd70346c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a795fe9-aabf-4d59-8c99-38fdfd70346c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"'\", \"\", text)\n",
        "    text = re.sub(\"(\\\\W)+\", \" \", text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "data['train'] = data['clean_text'].apply(clean_text)\n",
        "DATA_PATH = data['train']\n",
        "train_dataset = data['train']\n",
        "valid_dataset = data_val['Tweet']\n",
        "#data_val['val'] = data_val['clean_text'].apply(clean_txt)\n"
      ],
      "metadata": {
        "id": "UrWnV7H-G0IH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qkOsT1Bttqod"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the training data"
      ]
    },
    {
      "metadata": {
        "id": "OA6soGbGR__h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "68509250-2863-4a91-f8a2-55e3f6267897"
      },
      "cell_type": "code",
      "source": [
        "'''DATA_PATH = 'data/imdb_reviews.csv'\n",
        "if not Path(DATA_PATH).is_file():\n",
        "    gdd.download_file_from_google_drive(\n",
        "        file_id='1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz',\n",
        "        dest_path=DATA_PATH,\n",
        "    )'''"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"DATA_PATH = 'data/imdb_reviews.csv'\\nif not Path(DATA_PATH).is_file():\\n    gdd.download_file_from_google_drive(\\n        file_id='1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz',\\n        dest_path=DATA_PATH,\\n    )\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "tCmmgYaot2qM"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data\n",
        "\n",
        "This part might look a little weird as BERT expects the inputs of the model to have these `[CLS]` and `[SEP]` tokens. As well, BERT expects masks and segments.\n",
        "\n",
        "I found details on this convention [here](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py#L251), reproduced below.\n",
        "\n",
        "    The convention in BERT is:\n",
        "    (a) For sequence pairs:\n",
        "        tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "    (b) For single sequences:\n",
        "        tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        type_ids: 0     0   0   0  0     0 0\n",
        "\n",
        "    Where \"type_ids\" are used to indicate whether this is the first sequence or the second sequence. The embedding vectors for `type=0` and `type=1` were learned during pre-training and are added to the wordpiece embedding vector (and position vector). This is not *strictly* necessary since the [SEP] token unambigiously separates the sequences, but it makes it easier for the model to learn the concept of sequences.\n",
        "\n",
        "    For classification tasks, the first vector (corresponding to [CLS]) is used as as the \"sentence vector\". Note that this only makes sense because the entire model is fine-tuned.\n",
        "    \n",
        "    The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
        "    \n",
        "Note that `type_ids` corresponds to the term `segments`. Of course, if you read the paper these oddities will make more sense.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4jvvNAoYhSLi"
      },
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, data_path, max_len):\n",
        "        df = data\n",
        "\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        df['tokenized_text'] = df.train.progress_apply(self.tokenizer.tokenize)\n",
        "        \n",
        "        # Shorten to max length (Bert has a limit of 512); subtract two tokens for [CLS] and [SEP]\n",
        "        df.loc[:, 'tokenized_text'] = df.tokenized_text.str[:max_len - 2]\n",
        "        \n",
        "        # Add Bert-specific beginning and end tokens\n",
        "        df.loc[:, 'tokenized_text'] = df.tokenized_text.apply(\n",
        "            lambda tokens: ['[CLS]'] + tokens + ['[SEP]'],\n",
        "        )\n",
        "        \n",
        "        df['indexed_tokens'] = df.tokenized_text.progress_apply(\n",
        "            self.tokenizer.convert_tokens_to_ids,\n",
        "        )\n",
        "        \n",
        "        sequences = df.indexed_tokens.tolist()\n",
        "        max_sequence_length = max(len(x) for x in sequences)\n",
        "        \n",
        "        self.inputs_lst, self.masks, self.segments = [], [], []\n",
        "        for sequence in sequences:\n",
        "            self.inputs_lst.append(sequence + (max_sequence_length - len(sequence)) * [0])\n",
        "            self.masks.append(len(sequence) * [1] + (max_sequence_length - len(sequence)) * [0])\n",
        "            self.segments.append(max_sequence_length * [0])\n",
        "            \n",
        "        self.targets = df.Premise.tolist()\n",
        "        self.texts = df.train.tolist()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.inputs_lst[i], self.masks[i], self.segments[i], self.targets[i], self.texts[i]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs_lst)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QumAk05hSjIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16284196-476c-43bc-b1c1-9090e1efe53a"
      },
      "cell_type": "code",
      "source": [
        "# How many tokens long each sequence will be cut to\n",
        "# Shorter sequences will get the padding token <PAD>\n",
        "max_len = 128  #@param {type:\"slider\", min:16, max:512, step:2}\n",
        "\n",
        "dataset = SentimentDataset(DATA_PATH, max_len)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3556/3556 [00:01<00:00, 1802.07it/s]\n",
            "100%|██████████| 3556/3556 [00:00<00:00, 98676.45it/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jSZWT4PQt-gZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup the batches\n",
        "\n",
        "In order to avoid overloading the GPU (or CPU) memory, we have the model learn from batches of examples rather than all examples at once.\n",
        "\n",
        "First, however, we need to split our dataset into training, validation, and testing sets.\n",
        "\n",
        "- **Training**: data the model learns from\n",
        "- **Validation**: data to evaluate with for hyperparameter tuning (make sure the model doesn't overfit!)\n",
        "- **Testing**: data to evaluate the final performance of the model"
      ]
    },
    {
      "metadata": {
        "id": "rkZ8eA4PiBmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "18d76d7a-998f-43e5-d5f8-a62796d0720e"
      },
      "cell_type": "code",
      "source": [
        "#@title Splitting up the data\n",
        "\n",
        "'''def split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\n",
        "    \"\"\"Split dataset into train, validation, and test.\"\"\"\n",
        "    test_length = int(len(corpus) * valid_ratio)\n",
        "    valid_length = int(len(corpus) * test_ratio)\n",
        "    train_length = len(corpus) - valid_length - test_length\n",
        "    return random_split(\n",
        "        corpus, lengths=[train_length, valid_length, test_length],\n",
        "    )\n",
        "\n",
        "valid_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
        "test_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
        "\n",
        "# Train on only a subset of the data to reduce training time\n",
        "n_samples = 5000  #@param {type:\"integer\"}\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = split_train_valid_test(\n",
        "    dataset,\n",
        "    valid_ratio,\n",
        "    test_ratio,\n",
        ")\n",
        "train_dataset = Subset(train_dataset, torch.randperm(len(train_dataset))[:n_samples])\n",
        "len(train_dataset), len(valid_dataset), len(test_dataset)'''"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\\n    \"\"\"Split dataset into train, validation, and test.\"\"\"\\n    test_length = int(len(corpus) * valid_ratio)\\n    valid_length = int(len(corpus) * test_ratio)\\n    train_length = len(corpus) - valid_length - test_length\\n    return random_split(\\n        corpus, lengths=[train_length, valid_length, test_length],\\n    )\\n\\nvalid_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\\ntest_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\\n\\n# Train on only a subset of the data to reduce training time\\nn_samples = 5000  #@param {type:\"integer\"}\\n\\ntrain_dataset, valid_dataset, test_dataset = split_train_valid_test(\\n    dataset,\\n    valid_ratio,\\n    test_ratio,\\n)\\ntrain_dataset = Subset(train_dataset, torch.randperm(len(train_dataset))[:n_samples])\\nlen(train_dataset), len(valid_dataset), len(test_dataset)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "JyeIl7uPtiEO"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the data generators\n",
        "\n",
        "- **Batch size**: How many examples for the model to see at once. If it's too low, the model will train very slowly. If it's too high, you will run out of memory. The goal isn't necessarily to have the highest value you can get away with here. It really depends on the circumstances. For fine-tuning BERT, the recommended batch size is ony 32. Usually you will see batch sizes of 16, 32, 64, 128, or 256."
      ]
    },
    {
      "metadata": {
        "id": "ZIqnhuIuiFly"
      },
      "cell_type": "code",
      "source": [
        "#@title How many examples to load on the GPU at once\n",
        "\n",
        "def collate(batch):\n",
        "    inputs = torch.LongTensor([item[0] for item in batch])\n",
        "    mask = torch.LongTensor([item[1] for item in batch])\n",
        "    segment = torch.LongTensor([item[2] for item in batch])\n",
        "    target = torch.LongTensor([item[3] for item in batch])\n",
        "    text = [item[4] for item in batch]\n",
        "    \n",
        "    inputs, mask, segment, target = map(\n",
        "        lambda x: x.to(device),\n",
        "        (inputs, mask, segment, target),\n",
        "    )\n",
        "\n",
        "    return inputs, mask, segment, target, text\n",
        "\n",
        "batch_size = 32  #@param {type:\"integer\"}\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate)\n",
        "#test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JzHEyjEauBWy"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "We will train the smaller model `bert-base-uncased` as the larger one has problems fitting into memory. A multi-GPU setup is likely needed for training the larger model. You can find the full list of possible models [here](https://github.com/huggingface/pytorch-pretrained-BERT#loading-google-ai-or-openai-pre-trained-weigths-or-pytorch-dump).\n",
        "\n",
        "- **Learning rate**: How quickly the model learns. If it's too low, the model will learn very slowly. If it's too high, the model won't be able to learn at all. The goal is to have as high as value as we can get away with.\n",
        "\n",
        "Note that learning rate should be lower than what you maybe are used to (eg. 1e-5 instead of 1e-3), as we are only fine-tuning the BERT model instead of training it from scratch. We don't want the model's parameters to drastically change as that will likely result in a decrease in model performance."
      ]
    },
    {
      "metadata": {
        "id": "A3lCP_pXiX8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba6db8f-b65f-48d9-f2a7-181df727f49a"
      },
      "cell_type": "code",
      "source": [
        "#@title How big of steps the model takes while learning\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model = model.to(device)\n",
        "\n",
        "learning_rate = 0.001  #@param {type:\"number\"}\n",
        "\n",
        "param_optimizer = list(model.classifier.named_parameters()) \n",
        "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer]}]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install notebook"
      ],
      "metadata": {
        "id": "fvFpATlSVLtr",
        "outputId": "ff157f4f-f105-40a0-f2bb-999d1870834a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (5.3.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook) (4.10.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook) (1.8.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook) (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook) (5.3.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook) (5.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook) (5.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook) (23.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=5.2.0->notebook) (1.16.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook) (0.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook) (5.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook) (0.7.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook) (2.15.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook) (4.1.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook) (3.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "STlG1-DLib9j"
      },
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    train_loss = total = 0\n",
        "    for inputs, mask, segment, target, text in notebook.tqdm(train_loader,\n",
        "                                                             desc='Training',\n",
        "                                                             leave=False):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss = model(inputs, segment, mask, target)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        total += 1\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    return train_loss / total\n",
        "\n",
        "\n",
        "def validate_epoch(model, valid_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = total = 0\n",
        "        for inputs, mask, segment, target, text in notebook.tqdm(valid_loader,\n",
        "                                                                 desc='Validating',\n",
        "                                                                 leave=False):\n",
        "            loss = model(inputs, segment, mask, target)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            total += 1\n",
        "\n",
        "        return valid_loss / total"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limit the number of training epochs (training is slow)\n",
        "\n",
        "max_epochs = 1  #@param {type:\"slider\", min:1, max:10}\n",
        "\n",
        "n_epochs = 0\n",
        "train_losses, valid_losses = [], []\n",
        "while True:\n",
        "    train_loss = train_epoch(model, optimizer, train_loader)\n",
        "    valid_loss = validate_epoch(model, valid_loader)\n",
        "    \n",
        "    tqdm.write(\n",
        "        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.3f}\\tvalid_loss: {valid_loss:.3f}\\n',\n",
        "    )\n",
        "    \n",
        "    # Early stopping if the current valid_loss is\n",
        "    # greater than the last three valid losses\n",
        "    if len(valid_losses) > 2 and all(valid_loss > loss for loss in valid_losses[-3:]):\n",
        "        print('Stopping early')\n",
        "        break\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    n_epochs += 1\n",
        "    \n",
        "    if n_epochs >= max_epochs:\n",
        "        break"
      ],
      "metadata": {
        "id": "x5Z8814dQkCq",
        "outputId": "90206f16-9489-4054-d76e-509496c26402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-6589dd8e1b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-280cf90f2168>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, train_loader)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     for inputs, mask, segment, target, text in notebook.tqdm(train_loader,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                              \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                              leave=False):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'notebook' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4LL1rzM053Vx"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot the training and validation losses\n",
        "\n",
        "Typically validation loss will be higher than training loss as the model sees the training data but doesn't see the validation data. We use the validation curve to avoid overfitting to the training data: when validation loss starts to increase, stop training!"
      ]
    },
    {
      "metadata": {
        "id": "pt22lGJP2HVN"
      },
      "cell_type": "code",
      "source": [
        "epoch_ticks = range(1, n_epochs + 1)\n",
        "plt.plot(epoch_ticks, train_losses)\n",
        "plt.plot(epoch_ticks, valid_losses)\n",
        "plt.legend(['Train Loss', 'Valid Loss'])\n",
        "plt.title('Losses') \n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(epoch_ticks)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yUBkO8C2BRN"
      },
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ]
    },
    {
      "metadata": {
        "id": "JHGNXWy-1-VL"
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, mask, segment, target, text in test_loader:\n",
        "        loss = model(inputs, segment, mask, target)\n",
        "        logits = model(inputs, segment, mask)\n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        target = target.cpu().numpy()\n",
        "        \n",
        "        y_true.extend(predictions)\n",
        "        y_pred.extend(target)\n",
        "        \n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUne71xW2CvD"
      },
      "cell_type": "code",
      "source": [
        "flatten = lambda x: [sublst for lst in x for sublst in lst]\n",
        "inputs_lst, mask_lst, segment_lst, target_lst, text_lst = zip(*test_loader)\n",
        "inputs_lst, mask_lst, segment_lst, target_lst, text_lst = map(flatten, [inputs_lst, mask_lst, segment_lst, target_lst, text_lst])\n",
        "test_examples = list(zip(inputs_lst, mask_lst, segment_lst, target_lst, text_lst))\n",
        "\n",
        "def print_random_prediction(n=10):\n",
        "    to_emoji = lambda x: '😄' if x else '😡'\n",
        "    model.eval()\n",
        "    rows = []\n",
        "    for _ in range(n):\n",
        "        with torch.no_grad():\n",
        "            inputs, target, segment, target, text = random.choice(test_examples)\n",
        "\n",
        "            logits = model(inputs.unsqueeze(0))\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            prediction = np.argmax(logits, axis=1)[0]\n",
        "\n",
        "            predicted = to_emoji(prediction)\n",
        "            actual = to_emoji(target)\n",
        "            \n",
        "            row = f\"\"\"\n",
        "            <tr>\n",
        "            <td>{text}&nbsp;</td>\n",
        "            <td>{predicted}&nbsp;</td>\n",
        "            <td>{actual}&nbsp;</td>\n",
        "            </tr>\n",
        "            \"\"\"\n",
        "            rows.append(row)\n",
        "            \n",
        "    rows_joined = '\\n'.join(rows)\n",
        "    table = f\"\"\"\n",
        "<table>\n",
        "<tbody>\n",
        "<tr>\n",
        "<td><b>Review</b>&nbsp;</td>\n",
        "<td><b>Predicted</b>&nbsp;</td>\n",
        "<td><b>Actual</b>&nbsp;</td>\n",
        "</tr>\n",
        "{rows_joined}\n",
        "</tbody>\n",
        "</table>\n",
        "\"\"\"\n",
        "    display(HTML(table))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qyYqHA0U3Q_c"
      },
      "cell_type": "code",
      "source": [
        "print_random_prediction(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3cl6eBbKOQ6S"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}