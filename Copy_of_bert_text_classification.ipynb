{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of bert_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olumideaeo/Machine-Learning-Collection/blob/master/Copy_of_bert_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ee_x9Yq5hTuO",
        "outputId": "184cbc0d-0f51-43d0-fed3-918390607ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pymagnitude git+https://github.com/huggingface/pytorch-pretrained-BERT.git -q"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 16.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 68.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.1 MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pymagnitude (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy3gtheyFkHz",
        "outputId": "f5c0858a-f3b1-416c-8205-6215e4710f7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 16.9 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.22-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.11.0+cu113)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.22\n",
            "  Downloading botocore-1.27.22-py3-none-any.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 51.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.22->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.22->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 75.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.24.22 botocore-1.27.22 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vuNg51plR2GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a235fc1-632b-4212-8adf-cf09483e9b19"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_formats = ['svg']\n",
        "\n",
        "import random\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "#from pymagnitude import Magnitude\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "# If the machine you run this on has a GPU available with CUDA installed,\n",
        "# use it. Using a GPU for learning often leads to huge speedups in training.\n",
        "# See https://developer.nvidia.com/cuda-downloads for installing CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "VubeUOb2tZGU"
      },
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning BERT for Text Classification\n",
        "\n",
        "While transfer learning has had a huge impact on image-based deep learning tasks, transfer learning is still a relatively new concept in NLP. The idea is that you first train a large model on a huge amount of data, and then you fine-tune the model on a smaller subset of data.\n",
        "\n",
        "For example, we can train a large model on all of Wikipedia, then fine-tune our model on blog posts about statistics in order for our model to be able to identify the names of people in the blog posts about statistics. The model is able to leverage general understanding of language from Wikipedia to the specific task of identifying people in statistics blog posts.\n",
        "\n",
        "The architecture of BERT is similar, and potentially the next iteration of. The architecture of the GPT-2. The GPT-2 of course uses OpenAI's Transformer, however the model can only look foward when predicting the next word in a sequence. That is to say that is is not *bidirectional*. Therefore, the GPT-2 model is more suited just as a language model for generating text than it is as a text classifier. If we want to build a solid text classifier, we should hope that we are able to consider both words before and after when looking at the text.\n",
        "\n",
        "BERT is a **masked language model**. 15% of the input words are masked, or replaced by a special mask token. For every masked word, the model tries to use the output of the masked word to predict what the word is.\n",
        "\n",
        "![bert overview](http://jalammar.github.io/images/BERT-language-modeling-masked-lm.png)\n",
        "\n",
        "BERT can be setup to perform a number of NLP tasks such as text classification.\n",
        "\n",
        "![bert tasks](http://jalammar.github.io/images/bert-tasks.png)\n",
        "\n",
        "- Great blog post on BERT and the source of illustrations: [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/train.tsv', sep='\\t')\n",
        "data_val = pd.read_csv('/content/validation.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "jo6rDdCsGlYP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to lowercase\n",
        "data['clean_text']=data['Tweet'].str.lower()\n",
        "#remove URLS\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
        "#remove punctuations\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
        "#remove empty lines\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
        "#remove digits\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
        "#remove multiple spaces\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
        "#remove single character\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))"
      ],
      "metadata": {
        "id": "xHiQsSLPGr6z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "16_l5bChL9sC",
        "outputId": "7ab7faf7-68ec-4a14-95a8-a76ebfe2069d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweet                Claim  \\\n",
              "0    Ordered a mask that had a cute chain attached ...           face masks   \n",
              "1    Who is ready for some #baseball?  #BaseballisB...  stay at home orders   \n",
              "2    '@Mystere07623203 @va_shiva @Liberty13046 130,...           face masks   \n",
              "3    When they ask me what I did with my life I wil...           face masks   \n",
              "4    Taylor not putting her album in physical store...  stay at home orders   \n",
              "..                                                 ...                  ...   \n",
              "595  @BrianKempGA is one of the few #Governors that...           face masks   \n",
              "596  'I tested positive for Covid. Got it from a fr...           face masks   \n",
              "597  'If you are under retirement age, you have a *...  stay at home orders   \n",
              "598  '@TheLalasventure @doqholliday @realDonaldTrum...           face masks   \n",
              "599  @Caissie Obviously I was simply practicing my ...           face masks   \n",
              "\n",
              "      Stance  Premise  \n",
              "0      FAVOR        0  \n",
              "1       NONE        0  \n",
              "2      FAVOR        1  \n",
              "3      FAVOR        0  \n",
              "4      FAVOR        0  \n",
              "..       ...      ...  \n",
              "595  AGAINST        1  \n",
              "596    FAVOR        1  \n",
              "597  AGAINST        1  \n",
              "598    FAVOR        0  \n",
              "599    FAVOR        0  \n",
              "\n",
              "[600 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a795fe9-aabf-4d59-8c99-38fdfd70346c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Claim</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Premise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ordered a mask that had a cute chain attached ...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who is ready for some #baseball?  #BaseballisB...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>NONE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'@Mystere07623203 @va_shiva @Liberty13046 130,...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When they ask me what I did with my life I wil...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Taylor not putting her album in physical store...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>@BrianKempGA is one of the few #Governors that...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>'I tested positive for Covid. Got it from a fr...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>'If you are under retirement age, you have a *...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>'@TheLalasventure @doqholliday @realDonaldTrum...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>@Caissie Obviously I was simply practicing my ...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a795fe9-aabf-4d59-8c99-38fdfd70346c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a795fe9-aabf-4d59-8c99-38fdfd70346c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a795fe9-aabf-4d59-8c99-38fdfd70346c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"'\", \"\", text)\n",
        "    text = re.sub(\"(\\\\W)+\", \" \", text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "data['train'] = data['clean_text'].apply(clean_text)\n",
        "DATA_PATH = data['train']\n",
        "train_dataset = data['train']\n",
        "valid_dataset = data_val['Tweet']\n",
        "#data_val['val'] = data_val['clean_text'].apply(clean_txt)\n"
      ],
      "metadata": {
        "id": "UrWnV7H-G0IH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qkOsT1Bttqod"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the training data"
      ]
    },
    {
      "metadata": {
        "id": "OA6soGbGR__h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "68509250-2863-4a91-f8a2-55e3f6267897"
      },
      "cell_type": "code",
      "source": [
        "'''DATA_PATH = 'data/imdb_reviews.csv'\n",
        "if not Path(DATA_PATH).is_file():\n",
        "    gdd.download_file_from_google_drive(\n",
        "        file_id='1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz',\n",
        "        dest_path=DATA_PATH,\n",
        "    )'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"DATA_PATH = 'data/imdb_reviews.csv'\\nif not Path(DATA_PATH).is_file():\\n    gdd.download_file_from_google_drive(\\n        file_id='1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz',\\n        dest_path=DATA_PATH,\\n    )\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "tCmmgYaot2qM"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data\n",
        "\n",
        "This part might look a little weird as BERT expects the inputs of the model to have these `[CLS]` and `[SEP]` tokens. As well, BERT expects masks and segments.\n",
        "\n",
        "I found details on this convention [here](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py#L251), reproduced below.\n",
        "\n",
        "    The convention in BERT is:\n",
        "    (a) For sequence pairs:\n",
        "        tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "    (b) For single sequences:\n",
        "        tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        type_ids: 0     0   0   0  0     0 0\n",
        "\n",
        "    Where \"type_ids\" are used to indicate whether this is the first sequence or the second sequence. The embedding vectors for `type=0` and `type=1` were learned during pre-training and are added to the wordpiece embedding vector (and position vector). This is not *strictly* necessary since the [SEP] token unambigiously separates the sequences, but it makes it easier for the model to learn the concept of sequences.\n",
        "\n",
        "    For classification tasks, the first vector (corresponding to [CLS]) is used as as the \"sentence vector\". Note that this only makes sense because the entire model is fine-tuned.\n",
        "    \n",
        "    The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
        "    \n",
        "Note that `type_ids` corresponds to the term `segments`. Of course, if you read the paper these oddities will make more sense.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4jvvNAoYhSLi"
      },
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, data_path, max_len):\n",
        "        df = data\n",
        "\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        df['tokenized_text'] = df.train.progress_apply(self.tokenizer.tokenize)\n",
        "        \n",
        "        # Shorten to max length (Bert has a limit of 512); subtract two tokens for [CLS] and [SEP]\n",
        "        df.loc[:, 'tokenized_text'] = df.tokenized_text.str[:max_len - 2]\n",
        "        \n",
        "        # Add Bert-specific beginning and end tokens\n",
        "        df.loc[:, 'tokenized_text'] = df.tokenized_text.apply(\n",
        "            lambda tokens: ['[CLS]'] + tokens + ['[SEP]'],\n",
        "        )\n",
        "        \n",
        "        df['indexed_tokens'] = df.tokenized_text.progress_apply(\n",
        "            self.tokenizer.convert_tokens_to_ids,\n",
        "        )\n",
        "        \n",
        "        sequences = df.indexed_tokens.tolist()\n",
        "        max_sequence_length = max(len(x) for x in sequences)\n",
        "        \n",
        "        self.inputs_lst, self.masks, self.segments = [], [], []\n",
        "        for sequence in sequences:\n",
        "            self.inputs_lst.append(sequence + (max_sequence_length - len(sequence)) * [0])\n",
        "            self.masks.append(len(sequence) * [1] + (max_sequence_length - len(sequence)) * [0])\n",
        "            self.segments.append(max_sequence_length * [0])\n",
        "            \n",
        "        self.targets = df.Premise.tolist()\n",
        "        self.texts = df.train.tolist()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.inputs_lst[i], self.masks[i], self.segments[i], self.targets[i], self.texts[i]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs_lst)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QumAk05hSjIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449e93b7-fb70-42c2-aa2f-c05fee544c9c"
      },
      "cell_type": "code",
      "source": [
        "# How many tokens long each sequence will be cut to\n",
        "# Shorter sequences will get the padding token <PAD>\n",
        "max_len = 128  #@param {type:\"slider\", min:16, max:512, step:2}\n",
        "\n",
        "dataset = SentimentDataset(DATA_PATH, max_len)\n",
        "dataset_val = SentimentDataset(valid_dataset, max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 359310.05B/s]\n",
            "100%|██████████| 3556/3556 [00:02<00:00, 1761.87it/s]\n",
            "100%|██████████| 3556/3556 [00:00<00:00, 93973.13it/s]\n",
            "100%|██████████| 3556/3556 [00:01<00:00, 1828.20it/s]\n",
            "100%|██████████| 3556/3556 [00:00<00:00, 103582.48it/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jSZWT4PQt-gZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup the batches\n",
        "\n",
        "In order to avoid overloading the GPU (or CPU) memory, we have the model learn from batches of examples rather than all examples at once.\n",
        "\n",
        "First, however, we need to split our dataset into training, validation, and testing sets.\n",
        "\n",
        "- **Training**: data the model learns from\n",
        "- **Validation**: data to evaluate with for hyperparameter tuning (make sure the model doesn't overfit!)\n",
        "- **Testing**: data to evaluate the final performance of the model"
      ]
    },
    {
      "metadata": {
        "id": "rkZ8eA4PiBmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "18d76d7a-998f-43e5-d5f8-a62796d0720e"
      },
      "cell_type": "code",
      "source": [
        "#@title Splitting up the data\n",
        "\n",
        "'''def split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\n",
        "    \"\"\"Split dataset into train, validation, and test.\"\"\"\n",
        "    test_length = int(len(corpus) * valid_ratio)\n",
        "    valid_length = int(len(corpus) * test_ratio)\n",
        "    train_length = len(corpus) - valid_length - test_length\n",
        "    return random_split(\n",
        "        corpus, lengths=[train_length, valid_length, test_length],\n",
        "    )\n",
        "\n",
        "valid_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
        "test_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
        "\n",
        "# Train on only a subset of the data to reduce training time\n",
        "n_samples = 5000  #@param {type:\"integer\"}\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = split_train_valid_test(\n",
        "    dataset,\n",
        "    valid_ratio,\n",
        "    test_ratio,\n",
        ")\n",
        "train_dataset = Subset(train_dataset, torch.randperm(len(train_dataset))[:n_samples])\n",
        "len(train_dataset), len(valid_dataset), len(test_dataset)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\\n    \"\"\"Split dataset into train, validation, and test.\"\"\"\\n    test_length = int(len(corpus) * valid_ratio)\\n    valid_length = int(len(corpus) * test_ratio)\\n    train_length = len(corpus) - valid_length - test_length\\n    return random_split(\\n        corpus, lengths=[train_length, valid_length, test_length],\\n    )\\n\\nvalid_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\\ntest_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\\n\\n# Train on only a subset of the data to reduce training time\\nn_samples = 5000  #@param {type:\"integer\"}\\n\\ntrain_dataset, valid_dataset, test_dataset = split_train_valid_test(\\n    dataset,\\n    valid_ratio,\\n    test_ratio,\\n)\\ntrain_dataset = Subset(train_dataset, torch.randperm(len(train_dataset))[:n_samples])\\nlen(train_dataset), len(valid_dataset), len(test_dataset)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "JyeIl7uPtiEO"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the data generators\n",
        "\n",
        "- **Batch size**: How many examples for the model to see at once. If it's too low, the model will train very slowly. If it's too high, you will run out of memory. The goal isn't necessarily to have the highest value you can get away with here. It really depends on the circumstances. For fine-tuning BERT, the recommended batch size is ony 32. Usually you will see batch sizes of 16, 32, 64, 128, or 256."
      ]
    },
    {
      "metadata": {
        "id": "ZIqnhuIuiFly"
      },
      "cell_type": "code",
      "source": [
        "#@title How many examples to load on the GPU at once\n",
        "\n",
        "def collate(batch):\n",
        "    inputs = torch.LongTensor([item[0] for item in batch])\n",
        "    mask = torch.LongTensor([item[1] for item in batch])\n",
        "    segment = torch.LongTensor([item[2] for item in batch])\n",
        "    target = torch.LongTensor([item[3] for item in batch])\n",
        "    text = [item[4] for item in batch]\n",
        "    \n",
        "    inputs, mask, segment, target = map(\n",
        "        lambda x: x.to(device),\n",
        "        (inputs, mask, segment, target),\n",
        "    )\n",
        "\n",
        "    return inputs, mask, segment, target, text\n",
        "\n",
        "batch_size = 32  #@param {type:\"integer\"}\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate)\n",
        "valid_loader = DataLoader(dataset_val, batch_size=batch_size, collate_fn=collate)\n",
        "#test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JzHEyjEauBWy"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "We will train the smaller model `bert-base-uncased` as the larger one has problems fitting into memory. A multi-GPU setup is likely needed for training the larger model. You can find the full list of possible models [here](https://github.com/huggingface/pytorch-pretrained-BERT#loading-google-ai-or-openai-pre-trained-weigths-or-pytorch-dump).\n",
        "\n",
        "- **Learning rate**: How quickly the model learns. If it's too low, the model will learn very slowly. If it's too high, the model won't be able to learn at all. The goal is to have as high as value as we can get away with.\n",
        "\n",
        "Note that learning rate should be lower than what you maybe are used to (eg. 1e-5 instead of 1e-3), as we are only fine-tuning the BERT model instead of training it from scratch. We don't want the model's parameters to drastically change as that will likely result in a decrease in model performance."
      ]
    },
    {
      "metadata": {
        "id": "STlG1-DLib9j"
      },
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    train_loss = total = 0\n",
        "    for inputs, mask, segment, target, text in notebook.tqdm(train_loader,\n",
        "                                                             desc='Training',\n",
        "                                                             leave=False):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss = model(inputs, segment, mask, target)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        total += 1\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    return train_loss / total\n",
        "\n",
        "\n",
        "def validate_epoch(model, valid_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = total = 0\n",
        "        for inputs, mask, segment, target, text in notebook.tqdm(valid_loader,\n",
        "                                                                 desc='Validating',\n",
        "                                                                 leave=False):\n",
        "            loss = model(inputs, segment, mask, target)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            total += 1\n",
        "\n",
        "        return valid_loss / total"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title How big of steps the model takes while learning\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model = model.to(device)\n",
        "\n",
        "learning_rate = 0.001  #@param {type:\"number\"}\n",
        "\n",
        "param_optimizer = list(model.classifier.named_parameters()) \n",
        "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer]}]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMzZ5k66-oUL",
        "outputId": "dabc8273-3305-4b15-c207-9e4afe17d731"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:34<00:00, 11926254.06B/s]\n",
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limit the number of training epochs (training is slow)\n",
        "\n",
        "max_epochs = 3  #@param {type:\"slider\", min:1, max:10}\n",
        "\n",
        "n_epochs = 0\n",
        "train_losses, valid_losses = [], []\n",
        "'''while True:\n",
        "    train_loss = train_epoch(model, optimizer, train_loader)\n",
        "    valid_loss = validate_epoch(model, valid_loader)\n",
        "    \n",
        "    tqdm.write(\n",
        "        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.3f}\\tvalid_loss: {valid_loss:.3f}\\n',\n",
        "    )\n",
        "    \n",
        "    # Early stopping if the current valid_loss is\n",
        "    # greater than the last three valid losses\n",
        "    if len(valid_losses) > 2 and all(valid_loss > loss for loss in valid_losses[-3:]):\n",
        "        print('Stopping early')\n",
        "        break\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    n_epochs += 1\n",
        "    \n",
        "    if n_epochs >= max_epochs:\n",
        "        break'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "x5Z8814dQkCq",
        "outputId": "33c7ed2e-3fb7-4642-ce3c-9f249c8a5eab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"while True:\\n    train_loss = train_epoch(model, optimizer, train_loader)\\n    valid_loss = validate_epoch(model, valid_loader)\\n    \\n    tqdm.write(\\n        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.3f}\\tvalid_loss: {valid_loss:.3f}\\n',\\n    )\\n    \\n    # Early stopping if the current valid_loss is\\n    # greater than the last three valid losses\\n    if len(valid_losses) > 2 and all(valid_loss > loss for loss in valid_losses[-3:]):\\n        print('Stopping early')\\n        break\\n    \\n    train_losses.append(train_loss)\\n    valid_losses.append(valid_loss)\\n    \\n    n_epochs += 1\\n    \\n    if n_epochs >= max_epochs:\\n        break\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "4LL1rzM053Vx"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot the training and validation losses\n",
        "\n",
        "Typically validation loss will be higher than training loss as the model sees the training data but doesn't see the validation data. We use the validation curve to avoid overfitting to the training data: when validation loss starts to increase, stop training!"
      ]
    },
    {
      "metadata": {
        "id": "pt22lGJP2HVN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "571ba85d-0506-4f2c-b7e6-e18c00d577f5"
      },
      "cell_type": "code",
      "source": [
        "epoch_ticks = range(1, n_epochs + 1)\n",
        "'''plt.plot(epoch_ticks, train_losses)\n",
        "plt.plot(epoch_ticks, valid_losses)\n",
        "plt.legend(['Train Loss', 'Valid Loss'])\n",
        "plt.title('Losses') \n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')'''\n",
        "plt.xticks(epoch_ticks)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"241.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 241.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 241.518125 \nL 372.103125 241.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 228.439219 \nL 364.903125 228.439219 \nL 364.903125 10.999219 \nL 30.103125 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"me754c4ca62\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#me754c4ca62\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 232.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#me754c4ca62\" y=\"184.951219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(7.2 188.750438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#me754c4ca62\" y=\"141.463219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 145.262438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#me754c4ca62\" y=\"97.975219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 101.774437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#me754c4ca62\" y=\"54.487219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 58.286438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#me754c4ca62\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(7.2 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 228.439219 \nL 30.103125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 228.439219 \nL 364.903125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 228.439219 \nL 364.903125 228.439219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 10.999219 \nL 364.903125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2yUBkO8C2BRN"
      },
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ]
    },
    {
      "metadata": {
        "id": "JHGNXWy-1-VL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f63ed312-61c7-4206-9276-360d9ae1dce0"
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, mask, segment, target, text in valid_loader:\n",
        "        loss = model(inputs, segment, mask, target)\n",
        "        logits = model(inputs, segment, mask)\n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        target = target.cpu().numpy()\n",
        "        \n",
        "        y_true.extend(predictions)\n",
        "        y_pred.extend(target)\n",
        "        \n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.60      0.68      2922\n",
            "           1       0.12      0.26      0.17       634\n",
            "\n",
            "    accuracy                           0.54      3556\n",
            "   macro avg       0.46      0.43      0.42      3556\n",
            "weighted avg       0.67      0.54      0.59      3556\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3cl6eBbKOQ6S"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}